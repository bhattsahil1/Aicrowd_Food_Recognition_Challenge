{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drAPkKI-KPBg"
   },
   "source": [
    "#### SAHIL BHATT  \n",
    "#### Roll number : 2018111002  \n",
    "\n",
    "\n",
    "**WORK DONE**:\n",
    "1. Used Resnet-101 as pretrained model. Did not freeze any layers.  \n",
    "2. Added a Dropout layer just before the final classification layer.  \n",
    "3. Resized images to size 448x448.  \n",
    "4. Did not normalize images. Trained on the entire training dataset.  \n",
    "5. Augmented data by creating a dataset double the size of the original by horizontally flipping each image.  \n",
    "6. Trained the model for 6 epochs at a learning rate of 1e-5, 2 epochs at a learning rate of 1e-6, and one epoch at a learning rate of 1e-7.  \n",
    "7. Adam optimizer used, with cross-entropy loss.  \n",
    "\n",
    "**RESULTS**:\n",
    "Achieved the best F1-score (0.692) in the food recognition challenge, and significantly outperformed the previous best score of 0.676  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6Pcd11hJcPH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from PIL import Image, ImageEnhance\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "le = LabelEncoder()\n",
    "label_encoded = le.fit_transform(df['ClassName'])\n",
    "label_names = le.classes_\n",
    "df['label_encoded'] = label_encoded\n",
    "\n",
    "flip_df = df.copy(deep=True)\n",
    "df['fliplabel'] = [0]*len(df)\n",
    "flip_df['fliplabel'] = [1]*len(flip_df)\n",
    "merged_df = pd.concat([df,flip_df],ignore_index=True)\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, data_frame, root_dir,mode,transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        flip_value = self.data_frame.iloc[idx,-1]\n",
    "        if flip_value == 1:\n",
    "          image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if self.mode=='test':\n",
    "          label = None\n",
    "        else:\n",
    "          label = self.data_frame.iloc[idx, -2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return (image, label)\n",
    "\n",
    "food_train = FoodDataset(\n",
    "    data_frame=merged_df,\n",
    "    root_dir='image_data/train_images',\n",
    "    mode = 'train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((448,448)), \n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")\n",
    "\n",
    "def accuracy(outputs,labels):\n",
    "  _, preds = torch.max(outputs,dim=1)\n",
    "  return torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
    "\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "train_dl=DataLoader(food_train, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "food_test = FoodDataset(\n",
    "    data_frame=test_df,\n",
    "    root_dir='image_data/test_images',\n",
    "    mode = 'test',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((448,448)), \n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "test_dl = DataLoader(food_test, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "from torchvision import models\n",
    "modelresnet101 = models.resnet101(pretrained=True)\n",
    "num_ftrs = modelresnet101.fc.in_features\n",
    "modelresnet101.fc = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(num_ftrs, 1000)\n",
    ")\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "  def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  \n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "  def epoch_end(self, epoch, result):\n",
    "      print(\"Epoch [{}], train_loss: {:.4f}\".format(epoch, result))\n",
    "\n",
    "class ResnetModel(ImageClassificationBase):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.network = modelresnet101\n",
    "  def forward(self,x):\n",
    "    return self.network(x)\n",
    "\n",
    "resnet_model = ResnetModel()\n",
    "resnet_model = nn.DataParallel(resnet_model)\n",
    "# resnet_model.load_state_dict(torch.load('4482model_intel.pth'))\n",
    "print(\"GPU numbers\",torch.cuda.device_count())\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        print(device)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "def to_device(data,device):\n",
    "  if isinstance(data,(list,tuple)):\n",
    "    return [to_device(x,device) for x in data]\n",
    "  return data.to(device,non_blocking=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, opt_func=torch.optim.Adam):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.module.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        result = torch.stack(train_losses).mean().item()\n",
    "        model.module.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "resnet_model = to_device(resnet_model, device)\n",
    "num_epochs = 6\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.00001\n",
    "\n",
    "history = fit(num_epochs, lr, resnet_model, train_dl, opt_func)\n",
    "# torch.save(resnet_model.state_dict(), '4481model_intel.pth')\n",
    "history = fit(2,0.000001,resnet_model,train_dl,opt_func)\n",
    "# torch.save(resnet_model.state_dict(), '4482model_intel.pth')\n",
    "history = fit(1,0.0000001,resnet_model,train_dl,opt_func)\n",
    "# torch.save(resnet_model.state_dict(), '4483model_intel.pth')\n",
    "\n",
    "def predict_single(input,model):\n",
    "    input = to_device(input,device)\n",
    "    inputs = input.unsqueeze(0)   \n",
    "    model.eval()\n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach().cpu()\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "pred_list = []\n",
    "for img in food_test:\n",
    "    pred = predict_single(img[0],resnet_model)\n",
    "    predlabel = label_names[int(pred.item())]\n",
    "    # print(predlabel)\n",
    "    pred_list.append(predlabel)\n",
    "\n",
    "\n",
    "# dictionary of lists  \n",
    "dict = {'ClassName': pred_list}  \n",
    "       \n",
    "pred_df = pd.DataFrame(dict)\n",
    "pred_df.to_csv('submission.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2018111002_tournament_arc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
